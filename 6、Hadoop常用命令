hadoop fs 等同 hdfs dfs
dfsadmin
//查看文件系统的基本信息和统计信息   
hdfs dfsadmin -report

//进入安全模式 
hdfs dfsadmin -safemode enter

//安全模式不能上传文件
//安全模式是NameNode的一种状态，在这种状态下，NameNode是只读状态，不复制或删除块。
hdfs dfs -put jepson.log /
put: Cannot create file/jepson.log._COPYING_. Name node is in safe mode.

//退出安全模式 
hdfs dfsadmin -safemode leave
多台机器的磁盘存储分布不均匀解决方案
不加新机器，原机器的磁盘分布不均匀
  [hadoop@hadoop-01 ~]$ hdfs dfsadmin -setBalancerBandwidth  52428800
  Balancer bandwidth is set to 52428800

  [hadoop@hadoop-01 sbin]$ ./start-balancer.sh  
  等价
   [hadoop@hadoop-01 sbin]$ hdfs balancer 


   Apache Hadoop集群环境:  shell脚本每晚业务低谷时调度
  CDH集群环境: 忽略
网络和io最高的，也是最有风险性的:
加新机器，原机器的磁盘比如450G(500G),现在的新机器磁盘规格是5T
在业务低谷时，先将多台新机器加入到HDFS，做DN；
然后选一台的DN下架掉，等待hdfs自我修复块，恢复3份
一台机器的多个磁盘分布不均匀解决方案
无论加不加磁盘，且多块磁盘的分布不均匀  
hdfs diskbalancer -plan node1.mycluster.com
hdfs diskbalancer -execute /system/diskbalancer/nodename.plan.json        
将文件上传至hadoop的根目录/下载至本地
hadoop fs -put filename /     
hadoop fs -get /filename    
# '/'不是Linux的根目录，表示hadoop的根目录
例：
[hadoop@hadoop1 ~]$ hdfs dfs -put test.log /
[hadoop@hadoop1 data]$ hdfs dfs -get /test.log

[-moveFromLocal <localsrc> ... <dst>]
[-moveToLocal <src> <localdst>]
查看hadoop里的文件
hadoop fs -ls /
例：
[hadoop@hadoop1 ~]$ hadoop fs -ls /
Found 3 items
-rw-r--r--   1 hadoop supergroup          6 2017-12-19 11:18 /test.log
drwx------   - hadoop supergroup          0 2017-12-14 15:17 /tmp
drwxr-xr-x   - hadoop supergroup          0 2017-12-14 15:17 /user
查看hadoop里的文件的内容
hadoop fs -cat filename
例：
[hadoop@hadoop1 ~]$ hadoop fs -cat  /test.log
hello
创建文件夹
hadoop fs -mkdir -p /filename/filename
例：
[hadoop@hadoop1 ~]$ hadoop fs -mkdir -p /dwz01/dwz001
删除
[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]

// 配置回收站    
vi core-site.xml
<property>  
  <name>fs.trash.interval</name>  
  <value>10080</value>          # 回收站保留时间（分钟）
</property> 


// 测试
hadoop fs -rm -r -f /xxxx  ---》进入回收站，是可以恢复的
hadoop fs -rm -r -f -skipTrash /xxxx ---》不进入回收站，是不可以恢复的
例：
A.进入回收站
[hadoop@hadoop1 hadoop]$ hadoop fs -rm -r -f /test.log
17/12/19 14:06:06 INFO fs.TrashPolicyDefault: Moved: 'hdfs://192.168.137.130:9000/test.log' to trash at: hdfs://192.168.137.130:9000/user/hadoop/.Trash/Current/test.log
[hadoop@hadoop1 hadoop]$ hadoop fs -ls
Found 1 items
drwx------   - hadoop supergroup          0 2017-12-19 14:06 .Trash
[hadoop@hadoop1 data]$ hadoop fs -ls .Trash/Current
Found 1 items
-rw-r--r--   1 hadoop supergroup          6 2017-12-19 14:12 .Trash/Current/test.log
恢复刚刚删除的目录
[hadoop@hadoop1 hadoop]$ hadoop fs -mv /user/hadoop/.Trash/Current/test.log /
[hadoop@hadoop1 hadoop]$ hadoop fs -ls /
Found 4 items
drwxr-xr-x   - hadoop supergroup          0 2017-12-19 11:44 /dwz01
-rw-r--r--   1 hadoop supergroup          6 2017-12-19 11:18 /test.log
drwx------   - hadoop supergroup          0 2017-12-14 15:17 /tmp
drwxr-xr-x   - hadoop supergroup          0 2017-12-14 15:17 /user
B.不进入回收站
[hadoop@hadoop1 hadoop]$ hadoop fs -rm -r -f -skipTrash /test.log
Deleted /test.log
[hadoop@hadoop1 hadoop]$ hadoop fs -ls
Found 1 items
drwx------   - hadoop supergroup          0 2017-12-19 14:06 .Trash
[hadoop@hadoop1 hadoop]$ hadoop fs -ls .Trash
Found 1 items
drwx------   - hadoop supergroup          0 2017-12-19 14:09 .Trash/Current
[hadoop@hadoop1 hadoop]$ hadoop fs -ls .Trash/Current
[hadoop@hadoop1 hadoop]$         
